name: hpu-gaudi2
on:
  push:
    branches:
      - main

concurrency:
  cancel-in-progress: true
  group: ${{ github.workflow }}-${{ github.ref }}
jobs:
  unit-tests:
    container:
      image: vault.habana.ai/gaudi-docker/1.19.0/ubuntu22.04/habanalabs/pytorch-installer-2.5.1:latest
      options: --runtime=habana -e HABANA_VISIBLE_DEVICES=all -e OMPI_MCA_btl_vader_single_copy_mechanism=none
        --cap-add=sys_nice
      ports:
        - 80
    env:
      PT_HPU_LAZY_MODE: 0
      TEST_LIST: 'test_accelerator.py

        test_autotuning.py

        test_compression.py

        test_dist.py

        test_elastic.py

        test_ds_arguments.py

        test_run.py

        test_multinode_runner.py

        test_moe_tp.py

        test_monitor.py

        (test_zero_optimizer.py and (TestSaveTensorClone or TestZeRONonDistributed))

        (test_latest_checkpoint.py and test_missing_latest)

        test_reshape_checkpoint.py

        test_shared_weights.py

        test_sparse.py

        test_tag_validation.py

        test_pipe_module.py

        (test_flops_profiler.py and test_flops_profiler_in_inference)

        test_get_optim_files.py

        test_groups.py

        test_partition_balanced.py

        (test_adamw.py and TestAdamConfigs)

        test_coalesced_collectives.py

        test_activation_checkpointing_non_reentrant.py

        test_activation_checkpointing.py

        test_data.py

        (test_ds_config_dict.py and (TestBasicConfig or TestBatchConfig))

        test_ds_config_model.py

        test_mup_optimizers.py

        (test_pld.py and test_pld_schedule)

        test_runtime_utils.py

        test_pipe_schedule.py

        test_topology.py

        (test_ds_initialize.py and (TestClientOptimizer or TestClientLrScheduler))

        test_csr.py

        (test_fp16.py and (TestZeroEmptyGrad or TestZeroAllowUntestedOptimizer))

        (test_bf16.py and TestZeroDtypeCocktail)

        test_partition.py

        test_ignore_unused_parameters.py

        test_zero_config.py

        test_zero_context_ancestry.py

        (test_zero_context.py and not TestSerialContext)

        test_zero_dynamic_class.py

        test_zero_nesting_init.py

        test_zeropp.py

        (test_zero.py and (TestZero3ParamPartitioningLargeParam or TestZero3ParamPartitioningLargeParam))

        '
      TORCHINDUCTOR_COMPILE_THREADS: 1
    runs-on:
      - self-hosted
      - intel
      - gaudi2
    steps:
      - name: Start Energy Measurement
        uses: green-coding-solutions/eco-ci-energy-estimation@v4
        with:
          json-output: true
          task: start-measurement
      - uses: actions/checkout@v4
      - name: Check container state
        run: 'ldd --version

          hl-smi -L

          python -c "import torch; print(''torch:'', torch.__version__, torch)"

          python -c "import torch; print(''CUDA available:'', torch.cuda.is_available())"

          '
      - id: measurement-3
        name: Record Measurement After Check container state
        uses: green-coding-solutions/eco-ci-energy-estimation@v4
        with:
          json-output: true
          label: Check container state
          task: get-measurement
      - name: Install transformers
        run: 'git clone https://github.com/huggingface/transformers

          cd transformers

          # if needed switch to the last known good SHA until transformers@master
          is fixed

          git checkout 6c3f168b3

          git rev-parse --short HEAD

          pip install .

          '
      - id: measurement-5
        name: Record Measurement After Install transformers
        uses: green-coding-solutions/eco-ci-energy-estimation@v4
        with:
          json-output: true
          label: Install transformers
          task: get-measurement
      - name: Install deepspeed
        run: 'pip install .[dev,autotuning]

          ds_report

          '
      - id: measurement-7
        name: Record Measurement After Install deepspeed
        uses: green-coding-solutions/eco-ci-energy-estimation@v4
        with:
          json-output: true
          label: Install deepspeed
          task: get-measurement
      - name: Python environment
        run: 'pip list

          '
      - id: measurement-9
        name: Record Measurement After Python environment
        uses: green-coding-solutions/eco-ci-energy-estimation@v4
        with:
          json-output: true
          label: Python environment
          task: get-measurement
      - name: Unit tests
        run: 'unset TORCH_CUDA_ARCH_LIST # only jit compile for current arch

          cd tests

          export PT_HPU_LAZY_MODE=${PT_HPU_LAZY_MODE}

          export TORCHINDUCTOR_COMPILE_THREADS=${TORCHINDUCTOR_COMPILE_THREADS}

          TEST_LIST=$(echo "$TEST_LIST" | awk ''NF{printf "%s%s", (NR>1 ? " or " :
          ""), $0} END{if (NR>1) print ""}'')

          echo "TEST_LIST ${TEST_LIST}"

          pytest --verbose unit/ -k "${TEST_LIST}"

          '
      - id: measurement-11
        name: Record Measurement After Unit tests
        uses: green-coding-solutions/eco-ci-energy-estimation@v4
        with:
          json-output: true
          label: Unit tests
          task: get-measurement
      - id: display-measurement
        name: Display Energy Results
        uses: green-coding-solutions/eco-ci-energy-estimation@v4
        with:
          json-output: true
          task: display-results
      - name: Save Total Energy Consumption Data
        run: echo '${{ steps.final-measurement.outputs.data-total-json }}' > total_energy_consumption.json
      - name: Upload Energy Consumption Artifact
        uses: actions/upload-artifact@v4
        with:
          name: total-energy-consumption
          path: total_energy_consumption.json
permissions:
  contents: read
  issues: write
